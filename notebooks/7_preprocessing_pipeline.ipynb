{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3321122",
   "metadata": {},
   "source": [
    "\n",
    "# Unified Preprocessing Pipeline\n",
    "\n",
    "\n",
    "1. **Initial cleaning** – drop the `Unnamed: 0` column.\n",
    "2. **Missing value imputation** – fill missing numeric values with the median and missing categorical values with the most frequent category.\n",
    "3. **Numeric parsing** – extract numeric values from `Mileage`, `Engine`, `Power` and `New_Price` and convert them to `Mileage_Num`, `Engine_CC`, `Power_BHP` and `New_Price_Num`.\n",
    "4. **Name grouping** – collapse rare car names into an `Other` category and keep the top 50 most frequent names.\n",
    "5. **Encoding** – one‑hot encode the grouped `Name` and other categorical features: `Location`, `Fuel_Type`, `Transmission`, and `Owner_Type`.\n",
    "6. **Scaling** – standardize numeric features so they have zero mean and unit variance.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a27c144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size before outlier removal: 6019, after: 5017\n",
      "Prepared training feature matrix shape: (5017, 80)\n",
      "Prepared test feature matrix shape: (1234, 80)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import re\n",
    "\n",
    "# Custom transformers\n",
    "class InitialCleaner(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Remove irrelevant columns (e.g., 'Unnamed: 0').\"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if 'Unnamed: 0' in X.columns:\n",
    "            X = X.drop(columns=['Unnamed: 0'])\n",
    "        return X\n",
    "\n",
    "class NumericParser(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Parse textual numbers into numeric columns.\"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        def parse_numeric(value):\n",
    "            if pd.isnull(value):\n",
    "                return np.nan\n",
    "            match = re.search(r\"([0-9]*\\.?[0-9]+)\", str(value))\n",
    "            return float(match.group(1)) if match else np.nan\n",
    "        def parse_price(value):\n",
    "            if pd.isnull(value):\n",
    "                return np.nan\n",
    "            match = re.search(r\"([0-9]*\\.?[0-9]+)\", str(value))\n",
    "            if match:\n",
    "                num = float(match.group(1))\n",
    "                if 'Cr' in str(value) or 'cr' in str(value).lower():\n",
    "                    return num * 100  # convert crores to lakhs\n",
    "                return num\n",
    "            return np.nan\n",
    "        X['Mileage_Num'] = X['Mileage'].apply(parse_numeric)\n",
    "        X['Engine_CC'] = X['Engine'].apply(parse_numeric)\n",
    "        X['Power_BHP'] = X['Power'].apply(parse_numeric)\n",
    "        X['New_Price_Num'] = X['New_Price'].apply(parse_price)\n",
    "        return X\n",
    "\n",
    "class NameGrouper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Group rare car names into 'Other' and keep top_n names.\"\"\"\n",
    "    def __init__(self, top_n=50):\n",
    "        self.top_n = top_n\n",
    "        self.top_names_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        name_counts = X['Name'].value_counts()\n",
    "        self.top_names_ = name_counts.nlargest(self.top_n).index.tolist()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['Name_Grouped'] = X['Name'].apply(lambda x: x if x in self.top_names_ else 'Other')\n",
    "        return X\n",
    "\n",
    "# Function to remove outliers (to be applied on training data only)\n",
    "def remove_outliers(df, columns, factor=1.5):\n",
    "    cleaned_df = df.copy()\n",
    "    for col in columns:\n",
    "        Q1 = cleaned_df[col].quantile(0.25)\n",
    "        Q3 = cleaned_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        cleaned_df = cleaned_df[(cleaned_df[col] >= lower_bound) & (cleaned_df[col] <= upper_bound)]\n",
    "    return cleaned_df\n",
    "\n",
    "# Load raw data\n",
    "train_df = pd.read_csv('C:/Users/ASUS TUF/Desktop/SLIIT/Y2S1/AI and ML (IT2011)/ASSignment/train-data.csv', index_col=False)\n",
    "test_df = pd.read_csv('C:/Users/ASUS TUF/Desktop/SLIIT/Y2S1/AI and ML (IT2011)/ASSignment/test-data.csv', index_col=False)\n",
    "\n",
    "# Apply outlier removal on training data before pipeline fitting\n",
    "outlier_columns = ['Kilometers_Driven', 'Year', 'Price']\n",
    "train_df_no_outliers = remove_outliers(train_df, outlier_columns)\n",
    "print(f\"Training size before outlier removal: {train_df.shape[0]}, after: {train_df_no_outliers.shape[0]}\")\n",
    "\n",
    "# Define categorical and numeric feature lists (after parsing)\n",
    "categorical_features = ['Name_Grouped', 'Location', 'Fuel_Type', 'Transmission', 'Owner_Type']\n",
    "numeric_features = ['Year', 'Kilometers_Driven', 'Mileage_Num', 'Engine_CC', 'Power_BHP', 'Seats', 'New_Price_Num']\n",
    "\n",
    "# Define preprocessing for numeric and categorical features\n",
    "numeric_preprocess = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_preprocess = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "])\n",
    "\n",
    "# Combine into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_preprocess, numeric_features),\n",
    "    ('cat', categorical_preprocess, categorical_features),\n",
    "])\n",
    "\n",
    "# Create full pipeline\n",
    "full_pipeline = Pipeline([\n",
    "    ('initial_cleaner', InitialCleaner()),\n",
    "    ('numeric_parser', NumericParser()),\n",
    "    ('name_grouper', NameGrouper(top_n=50)),\n",
    "    ('preprocessor', preprocessor),\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the cleaned training data\n",
    "X_train = train_df_no_outliers.drop(columns=['Price'])\n",
    "y_train = train_df_no_outliers['Price']\n",
    "\n",
    "full_pipeline.fit(X_train)\n",
    "\n",
    "# Transform the training and test sets\n",
    "X_train_prepared = full_pipeline.transform(X_train)\n",
    "X_test_prepared = full_pipeline.transform(test_df)\n",
    "\n",
    "print(f\"Prepared training feature matrix shape: {X_train_prepared.shape}\")\n",
    "print(f\"Prepared test feature matrix shape: {X_test_prepared.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab1b3976-ef59-4bae-891d-e06e22f33a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Final processed datasets saved to results/outputs/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# === 1. Load Data ===\n",
    "train_df = pd.read_csv(r\"C:/Users/ASUS TUF/Desktop/SLIIT/Y2S1/AI and ML (IT2011)/ASSignment/train-data.csv\")\n",
    "test_df  = pd.read_csv(r\"C:/Users/ASUS TUF/Desktop/SLIIT/Y2S1/AI and ML (IT2011)/ASSignment/test-data.csv\")\n",
    "\n",
    "# Example preprocessing: convert textual numeric columns\n",
    "for col in [\"Mileage\", \"Engine\", \"Power\", \"New_Price\"]:\n",
    "    if col in train_df.columns:\n",
    "        train_df[col] = train_df[col].astype(str).str.extract(r'([\\d\\.]+)').astype(float)\n",
    "        test_df[col]  = test_df[col].astype(str).str.extract(r'([\\d\\.]+)').astype(float)\n",
    "\n",
    "# === 2. Feature Groups ===\n",
    "numeric_features = ['Year','Kilometers_Driven','Mileage','Engine','Power','Seats']\n",
    "categorical_features = ['Name','Location','Fuel_Type','Transmission','Owner_Type']\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# === 3. Fit & Transform ===\n",
    "X_train_processed = preprocessor.fit_transform(train_df)\n",
    "X_test_processed  = preprocessor.transform(test_df)\n",
    "\n",
    "# Get feature names\n",
    "feature_names = (\n",
    "    numeric_features +\n",
    "    list(preprocessor.named_transformers_['cat']\n",
    "         .named_steps['encoder']\n",
    "         .get_feature_names_out(categorical_features))\n",
    ")\n",
    "\n",
    "# Convert to DataFrames\n",
    "train_processed_df = pd.DataFrame(X_train_processed, columns=feature_names)\n",
    "test_processed_df  = pd.DataFrame(X_test_processed,  columns=feature_names)\n",
    "\n",
    "# === 4. Save Outputs ===\n",
    "os.makedirs(\"results/outputs\", exist_ok=True)\n",
    "train_processed_df.to_csv(\"C:/Users/ASUS TUF/Desktop/SLIIT/Y2S1/AI and ML (IT2011)/ASSignment/Code/results/outputs/train_processed.csv\", index=False)\n",
    "test_processed_df.to_csv(\"C:/Users/ASUS TUF/Desktop/SLIIT/Y2S1/AI and ML (IT2011)/ASSignment/Code/results/outputs/test_processed.csv\", index=False)\n",
    "\n",
    "print(\"✅ Final processed datasets saved to results/outputs/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "052e246d-69c6-484a-9314-57ce3e7fe36b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
