{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3321122",
   "metadata": {},
   "source": [
    "\n",
    "# Unified Preprocessing Pipeline\n",
    "\n",
    "This notebook integrates all preprocessing steps implemented by individual members into a single, reusable pipeline.  Each transformation is encapsulated in a custom transformer class or scikit‑learn component so that it can be applied consistently during training and inference.  The pipeline performs the following operations:\n",
    "\n",
    "1. **Initial cleaning** – drop the `Unnamed: 0` column.\n",
    "2. **Missing value imputation** – fill missing numeric values with the median and missing categorical values with the most frequent category.\n",
    "3. **Numeric parsing** – extract numeric values from `Mileage`, `Engine`, `Power` and `New_Price` and convert them to `Mileage_Num`, `Engine_CC`, `Power_BHP` and `New_Price_Num`.\n",
    "4. **Name grouping** – collapse rare car names into an `Other` category and keep the top 50 most frequent names.\n",
    "5. **Encoding** – one‑hot encode the grouped `Name` and other categorical features: `Location`, `Fuel_Type`, `Transmission`, and `Owner_Type`.\n",
    "6. **Scaling** – standardize numeric features so they have zero mean and unit variance.\n",
    "\n",
    "> **Note:** Outlier removal should be applied manually to the training set before fitting the pipeline.  Removing observations inside a transformer is not advised because it may misalign feature matrices with target labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "import re\n",
    "\n",
    "# Custom transformers\n",
    "class InitialCleaner(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Remove irrelevant columns (e.g., 'Unnamed: 0').\"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        if 'Unnamed: 0' in X.columns:\n",
    "            X = X.drop(columns=['Unnamed: 0'])\n",
    "        return X\n",
    "\n",
    "class NumericParser(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Parse textual numbers into numeric columns.\"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        def parse_numeric(value):\n",
    "            if pd.isnull(value):\n",
    "                return np.nan\n",
    "            match = re.search(r\"([0-9]*\\.?[0-9]+)\", str(value))\n",
    "            return float(match.group(1)) if match else np.nan\n",
    "        def parse_price(value):\n",
    "            if pd.isnull(value):\n",
    "                return np.nan\n",
    "            match = re.search(r\"([0-9]*\\.?[0-9]+)\", str(value))\n",
    "            if match:\n",
    "                num = float(match.group(1))\n",
    "                if 'Cr' in str(value) or 'cr' in str(value).lower():\n",
    "                    return num * 100  # convert crores to lakhs\n",
    "                return num\n",
    "            return np.nan\n",
    "        X['Mileage_Num'] = X['Mileage'].apply(parse_numeric)\n",
    "        X['Engine_CC'] = X['Engine'].apply(parse_numeric)\n",
    "        X['Power_BHP'] = X['Power'].apply(parse_numeric)\n",
    "        X['New_Price_Num'] = X['New_Price'].apply(parse_price)\n",
    "        return X\n",
    "\n",
    "class NameGrouper(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Group rare car names into 'Other' and keep top_n names.\"\"\"\n",
    "    def __init__(self, top_n=50):\n",
    "        self.top_n = top_n\n",
    "        self.top_names_ = None\n",
    "    def fit(self, X, y=None):\n",
    "        name_counts = X['Name'].value_counts()\n",
    "        self.top_names_ = name_counts.nlargest(self.top_n).index.tolist()\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['Name_Grouped'] = X['Name'].apply(lambda x: x if x in self.top_names_ else 'Other')\n",
    "        return X\n",
    "\n",
    "# Function to remove outliers (to be applied on training data only)\n",
    "def remove_outliers(df, columns, factor=1.5):\n",
    "    cleaned_df = df.copy()\n",
    "    for col in columns:\n",
    "        Q1 = cleaned_df[col].quantile(0.25)\n",
    "        Q3 = cleaned_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - factor * IQR\n",
    "        upper_bound = Q3 + factor * IQR\n",
    "        cleaned_df = cleaned_df[(cleaned_df[col] >= lower_bound) & (cleaned_df[col] <= upper_bound)]\n",
    "    return cleaned_df\n",
    "\n",
    "# Load raw data\n",
    "train_df = pd.read_csv('../data/train-data.csv', index_col=False)\n",
    "test_df = pd.read_csv('../data/test-data.csv', index_col=False)\n",
    "\n",
    "# Apply outlier removal on training data before pipeline fitting\n",
    "outlier_columns = ['Kilometers_Driven', 'Year', 'Price']\n",
    "train_df_no_outliers = remove_outliers(train_df, outlier_columns)\n",
    "print(f\"Training size before outlier removal: {train_df.shape[0]}, after: {train_df_no_outliers.shape[0]}\")\n",
    "\n",
    "# Define categorical and numeric feature lists (after parsing)\n",
    "categorical_features = ['Name_Grouped', 'Location', 'Fuel_Type', 'Transmission', 'Owner_Type']\n",
    "numeric_features = ['Year', 'Kilometers_Driven', 'Mileage_Num', 'Engine_CC', 'Power_BHP', 'Seats', 'New_Price_Num']\n",
    "\n",
    "# Define preprocessing for numeric and categorical features\n",
    "numeric_preprocess = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "])\n",
    "\n",
    "categorical_preprocess = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore')),\n",
    "])\n",
    "\n",
    "# Combine into a ColumnTransformer\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_preprocess, numeric_features),\n",
    "    ('cat', categorical_preprocess, categorical_features),\n",
    "])\n",
    "\n",
    "# Create full pipeline\n",
    "full_pipeline = Pipeline([\n",
    "    ('initial_cleaner', InitialCleaner()),\n",
    "    ('numeric_parser', NumericParser()),\n",
    "    ('name_grouper', NameGrouper(top_n=50)),\n",
    "    ('preprocessor', preprocessor),\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the cleaned training data\n",
    "X_train = train_df_no_outliers.drop(columns=['Price'])\n",
    "y_train = train_df_no_outliers['Price']\n",
    "\n",
    "full_pipeline.fit(X_train)\n",
    "\n",
    "# Transform the training and test sets\n",
    "X_train_prepared = full_pipeline.transform(X_train)\n",
    "X_test_prepared = full_pipeline.transform(test_df)\n",
    "\n",
    "print(f\"Prepared training feature matrix shape: {X_train_prepared.shape}\")\n",
    "print(f\"Prepared test feature matrix shape: {X_test_prepared.shape}\")\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
